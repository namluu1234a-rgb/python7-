可以自行认领工作任务。一共是7个py文件 获取股价：get_market_data  爬虫：crawl+bilibili_crawl  数据清理及nlp：nlp+bilibili_nlp  汇总：processing 可视化：visualize

因为我是开着梯子vpn跑的ai，所以有些代码会加上屏蔽代理，爬虫用的都是Chrome浏览器，你们修改的时候可以改成edge或者自己常用的浏览器，只要能打开就行

我爬去的股吧文本，因为东方财富网股吧是不显示年份的，他只显示月日，只能点进帖子内才能看到年份，爬虫写不出来点进去再出来再爬取的功能，如果你们能完成就更好了，我用的是笨办法：人工找到要爬取的页码然后把每一个文本都爬取下来，让在raw_xxxxxx.csv里面了

我就不改每一个代码了，我就只改我自己的两个nlp的代码，需要修改：1.删掉所有注释，你可以后期手动自己加，AI写的注释太明显，学会了以后就删  2.去掉所有验证性的代码，只保留运行的代码，比如ai写的代码会反复验证，要删掉要不然老师一眼就看出来了  Q w Q


# python7-
小组作业
# Project Sentinel: A股上市公司舆情信息有效性审计系统 (第7组)

## 1. 项目简介
本项目属于《Python在财务中的应用》课程作业。我们基于行为金融学的“有限关注理论”，构建了一套量化分析系统，旨在识别A股市场中的“有效舆情”与“无效噪音”。
系统通过爬取股吧数据与股价进行对冲分析，计算“背离度”因子，最终生成可视化的审计仪表盘。

## 2. 环境配置 (Requirements)
在运行代码前，请确保安装以下 Python 库：
pip install pandas numpy selenium beautifulsoup4 snownlp jieba wordcloud plotly streamlit webdriver-manager

*注意：爬虫脚本需要电脑上安装有 Chrome 或 Edge 浏览器。*

---

## 3. 操作流程 (由上至下运行)

整个项目分为三个阶段，请严格按照以下顺序执行脚本：

### [第一步：数据采集]
1. **运行 `get_market_data.py`** (如有)
   - 作用：获取赛力斯、圣龙、九阳的股价行情数据（OHLCV、CAR等）。
   - 输出：在 data 目录下生成 market_xxxx.csv。
   
2. **运行 `get_sentiment_data.py`**
   - 作用：启动“多线程爬虫”，抓取东方财富股吧的舆情数据。
   - 逻辑：采用了“区间回溯法”，针对2023年舆情爆发期进行精准采集。
   - 输出：在 data 目录下生成 sentiment_xxxx.csv。

### [第二步：数据清洗与建模]
3. **运行 `processing.py`**
   - 作用：将舆情数据与股价数据合并，进行清洗、对齐。
   - 核心：执行 NLP 分词（jieba）、情感打分（SnowNLP），并计算核心指标。
   - 输出：生成用于可视化的最终底稿 final_xxxx.csv 和 combined_timeline.csv。

### [第三步：可视化审计演示]
4. **运行 `app.py`**
   - 命令：在终端输入 `streamlit run app.py`
   - 作用：启动交互式审计大屏，这是我们要展示给老师看的最终界面。

---

## 4. 核心代码原理 (报告撰写素材)

**队友请注意**：以下内容解释了代码背后的金融逻辑，可用于小组报告的“模型构建”或“技术路线”章节。

### (1) 关于爬虫逻辑 (get_sentiment_data.py)
* **技术亮点**：采用了 Selenium + 8线程并发技术，极大提升了抓取效率。
* **年份处理**：由于股吧列表页不显示年份，我们采用了**“人工锚定区间法”**（Manual Anchor Strategy）。我们在代码中锁定了2023年舆情爆发时的特定页码范围（如赛力斯3208-3654页），确保了数据的时间纯净度。

### (2) 关于因子构建 (processing.py)
* **舆情加权 (Weighted Buzz)**：
    我们没有简单使用情感均值，而是构建了公式：`加权情感 = 情感得分 × (阅读量 + 1)`。
    *原理*：基于投资者关注度理论，无人阅读的帖子只是市场噪音，高阅读量的帖子才具有定价影响力。
* **背离度 (Divergence Indicator)**：
    代码中计算的核心风险指标：`背离度 = 累积热度 / (|股价涨幅| + 0.01)`。
    *原理*：当舆情热度极高（分子大），但股价几乎不动（分母小）时，背离度飙升。这精准量化了“九阳股份”案例中“哈基米”梗造成的无效噪音——只有热闹，没有资金流入。

### (3) 关于可视化逻辑 (app.py)
* **时空伴随图**：我们利用 Plotly 的动画帧技术，展示了个股在“热度-收益”坐标系下的动态轨迹。
    * **向右上方移动**：代表“价值共振”（舆情推动股价，如赛力斯）。
    * **向右下方移动**：代表“噪音陷阱”（热度高但股价不涨，如九阳）。
* **NLP 语义云**：使用了 jieba 分词并挂载了金融自定义词典（如“遥遥领先”、“龙字辈”），确保词云展示的是真实的金融语义，而非无意义的虚词。

---

## 5. 文件目录结构
.
├── get_market_data.py     # 获取股价数据
├── get_sentiment_data.py  # 获取舆情数据 (爬虫)
├── processing.py          # 数据清洗与因子计算
├── app.py                 # Streamlit 可视化终端
├── real_data/             # [自动生成] 数据存放目录
│   ├── market_xxxx.csv
│   ├── sentiment_xxxx.csv
│   ├── final_xxxx.csv
│   └── combined_timeline.csv
└── README.txt             # 说明文档

© 2025 Python Financial Analysis Group 7
