import pandas as pd
import numpy as np
import os
import jieba
from snownlp import SnowNLP
from wordcloud import WordCloud

# é…ç½®è·¯å¾„
RAW_DIR = "./raw_data_lake"  # æ¥æº
REAL_DIR = "./real_data"  # ç»“æœ
if not os.path.exists(REAL_DIR): os.makedirs(REAL_DIR)

# è‚¡ç¥¨åŠåœç”¨è¯ (é˜²æ­¢è¯äº‘å‡ºç°æ— å…³è¯)
STOCKS = {
    '002242': {'name': 'ä¹é˜³è‚¡ä»½', 'stop': ['ä¹é˜³', 'è‚¡ä»½', 'è‚¡ç¥¨', 'ä»Šå¤©', 'ä¸»åŠ›', 'ä»€ä¹ˆ']},
    '601127': {'name': 'èµ›åŠ›æ–¯', 'stop': ['èµ›åŠ›æ–¯', 'æ±½è½¦', 'è‚¡ç¥¨', 'ä»€ä¹ˆæ—¶å€™', 'å¤šå°‘', 'æˆ‘ä»¬']},
    '01810': {'name': 'å°ç±³é›†å›¢', 'stop': ['å°ç±³', 'é›†å›¢', 'æ¸¯è‚¡', '01810', 'è‚¡ä»·', 'æ€ä¹ˆ']}
}


def get_sentiment(text):
    """è®¡ç®—æƒ…æ„Ÿåˆ†"""
    try:
        return SnowNLP(str(text)).sentiments
    except:
        return 0.5


def process_nlp():
    print("ğŸš€ å¯åŠ¨ NLP åˆ†æå·¥å‚...")

    for code, conf in STOCKS.items():
        name = conf['name']
        raw_path = f"{RAW_DIR}/raw_{code}.csv"

        if not os.path.exists(raw_path):
            print(f"âš ï¸ è·³è¿‡ {name}: æœªæ‰¾åˆ° {raw_path}ï¼Œè¯·å…ˆè¿è¡Œ crawl.py")
            continue

        print(f"\nğŸ”¨ æ­£åœ¨ç²¾ç‚¼: {name} ...")

        # 1. è¯»å–åŸå§‹æ•°æ®
        df = pd.read_csv(raw_path)

        # 2. æ‰¹é‡æƒ…æ„Ÿæ‰“åˆ†
        print(f"   -> æ­£åœ¨è®¡ç®— {len(df)} æ¡æ•°æ®çš„æƒ…æ„Ÿåˆ†...")
        df['sentiment'] = df['title'].apply(get_sentiment)

        # 3. ç”Ÿæˆè¯äº‘å›¾ç‰‡
        print(f"   -> æ­£åœ¨ç”Ÿæˆè¯äº‘...")
        text_content = " ".join(df['title'].astype(str).tolist())
        words = jieba.lcut(text_content)
        clean_words = [w for w in words if len(w) > 1 and w not in conf['stop']]

        wc = WordCloud(font_path="C:/Windows/Fonts/simhei.ttf",
                       background_color="white", width=800, height=500)
        wc.generate(" ".join(clean_words))
        wc.to_file(f"{REAL_DIR}/wc_{code}.png")

        # 4. èšåˆä¸ºæ—¥åº¦æ•°æ®
        df['date'] = pd.to_datetime(df['date'], errors='coerce')
        df = df.dropna(subset=['date'])

        # è®¡ç®—åŠ æƒåˆ†ï¼š(æƒ…æ„Ÿ * çƒ­åº¦)
        df['weighted_score_raw'] = df['sentiment'] * (df['read_count'] + 1)

        daily = df.groupby('date').agg({
            'sentiment': 'mean',  # å¹³å‡æƒ…æ„Ÿ
            'read_count': 'sum',  # æ€»çƒ­åº¦ (Buzz)
            'weighted_score_raw': 'sum'  # æ€»åŠ æƒåˆ†
        })

        # å½’ä¸€åŒ–æ—¥åº¦åŠ æƒæƒ…æ„Ÿ
        daily['weighted_score'] = daily['weighted_score_raw'] / (daily['read_count'] + 1)

        # ä¿å­˜
        save_path = f"{REAL_DIR}/sentiment_{code}.csv"
        daily.to_csv(save_path)
        print(f"âœ… {name} å¤„ç†å®Œæ¯•ï¼å·²å­˜å…¥ {save_path}")

    print("\nğŸ‰ NLP ä»»åŠ¡å…¨éƒ¨å®Œæˆï¼")


if __name__ == "__main__":
    process_nlp()
