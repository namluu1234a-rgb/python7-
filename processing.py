import pandas as pd
import numpy as np
import os
from scipy.stats import pearsonr
from wordcloud import WordCloud
import matplotlib.pyplot as plt

plt.rcParams['font.sans-serif'] = ['SimHei']
plt.rcParams['axes.unicode_minus'] = False
DATA_DIR = "./real_data"

STOCKS = {
    '002242': {'name': 'ä¹é˜³è‚¡ä»½', 'type': 'å™ªéŸ³å‹'},
    '601127': {'name': 'èµ›åŠ›æ–¯', 'type': 'ä»·å€¼å‹'},
    '603178': {'name': 'åœ£é¾™è‚¡ä»½', 'type': 'åšå¼ˆå‹'}
}


def process_final():
    print("ğŸš€ å¯åŠ¨æ•°æ®æ¸…æ´—ä¸å…¨æ™¯æ•´åˆå¼•æ“ (ä¿®å¤ç‰ˆ)...")

    all_data_list = []

    for code, info in STOCKS.items():
        name = info['name']
        s_path = f"{DATA_DIR}/sentiment_{code}.csv"
        m_path = f"{DATA_DIR}/market_{code}.csv"

        if not os.path.exists(s_path) or not os.path.exists(m_path):
            print(f"âš ï¸ è·³è¿‡ {name}")
            continue

        # 1. è¯»å–ä¸æ¸…æ´—
        df_s = pd.read_csv(s_path, index_col=0)
        df_m = pd.read_csv(m_path, index_col=0)

        df_s.index = pd.to_datetime(df_s.index, errors='coerce')
        df_m.index = pd.to_datetime(df_m.index, errors='coerce')
        df_s = df_s.dropna(how='all')

        # 2. åˆå¹¶
        df = pd.merge(df_m, df_s, left_index=True, right_index=True, how='inner')
        if len(df) < 5: continue

        # 3. ç»Ÿä¸€å› å­è®¡ç®—
        if code in ['601127', '603178']:
            # çƒ­é—¨è‚¡ç”¨çƒ­åº¦ç´¯ç§¯
            raw = df['total_buzz'].cumsum()
        else:
            # ä¹é˜³ä¹Ÿç”¨çƒ­åº¦ç´¯ç§¯ï¼Œæ”¾å¤§ä¸€ç‚¹æ•°å€¼ä»¥ä¾¿è§‚å¯Ÿ
            raw = df['total_buzz'].cumsum() * 2

        df['cum_factor'] = raw.bfill().fillna(0)

        # ã€å…³é”®ä¿®å¤ã€‘APP éœ€è¦è¯»å– 'meme_heat' åˆ—ï¼Œè¿™é‡Œå¿…é¡»èµ‹å€¼
        df['meme_heat'] = df['cum_factor']

        # 4. è®¡ç®—å…¶ä»–å±•ç¤ºæŒ‡æ ‡
        # èƒŒç¦»åº¦
        df['divergence'] = df['cum_factor'] / (df['CAR'].abs() + 0.01)

        # å½’ä¸€åŒ– (0-100åˆ†åˆ¶ï¼Œç”¨äºåŠ¨æ€æ°”æ³¡å›¾)
        df['Heat_Score'] = (df['cum_factor'] - df['cum_factor'].min()) / (
                    df['cum_factor'].max() - df['cum_factor'].min()) * 100
        df['CAR_Score'] = df['CAR'] * 100

        # ä¿å­˜å•æ–‡ä»¶
        df.to_csv(f"{DATA_DIR}/final_{code}.csv")

        # 5. å‡†å¤‡åˆå¹¶æ•°æ® (ç”¨äºåŠ¨æ€å›¾)
        df['Name'] = name
        df['Type'] = info['type']
        df['Date_Str'] = df.index.strftime('%Y-%m-%d')

        df_reset = df.reset_index()
        # ç¡®ä¿åŒ…å« app éœ€è¦çš„æ‰€æœ‰åˆ—
        all_data_list.append(
            df_reset[['date', 'Date_Str', 'Name', 'Type', 'Heat_Score', 'CAR_Score', 'total_buzz', 'meme_heat', 'CAR']])

        # 6. ç”Ÿæˆè¯äº‘
        wc = WordCloud(font_path="C:/Windows/Fonts/simhei.ttf", background_color="white", width=600, height=400)
        if code == '601127':
            words = {'é¥é¥é¢†å…ˆ': 100, 'åä¸º': 90, 'M7': 80, 'å¤§å®š': 60}
        elif code == '603178':
            words = {'é¾™å­—è¾ˆ': 100, 'æ¶¨åœ': 90, 'åœ£é¾™': 80, 'è·¨å¹´å¦–': 70}
        else:
            words = {'å“ˆåŸºç±³': 100, 'ç¦»è°±': 50, 'ç”šè‡³': 40, 'å¥½ç©': 30}
        wc.generate_from_frequencies(words)
        wc.to_file(f"{DATA_DIR}/wc_{code}.png")

    # 7. ç”Ÿæˆå…¨æ™¯æ—¶é—´è½´æ•°æ®
    if all_data_list:
        full_df = pd.concat(all_data_list)
        full_df = full_df.sort_values('date')
        full_df.to_csv(f"{DATA_DIR}/combined_timeline.csv", index=False)
        print("âœ… æ•°æ®ä¿®å¤å®Œæˆï¼è¯·é‡æ–°è¿è¡Œ streamlit run app.py")


if __name__ == "__main__":
    process_final()
