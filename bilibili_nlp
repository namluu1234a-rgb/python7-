import pandas as pd
import numpy as np
import os
import re
import datetime
from snownlp import SnowNLP

# ===========================
# 1. é…ç½®ï¼šä¸¥æ ¼çš„æ—¶é—´çª—å£
# ===========================
# ç¡®ä¿åªä¿ç•™å±äºè¯¥äº‹ä»¶â€œé»„é‡‘çˆ†å‘æœŸâ€çš„è§†é¢‘
TIME_WINDOWS = {
    '002242': ('2025-10-01', '2025-12-31'),  # ä¹é˜³ (å½“ä¸‹ï¼ŒBç«™æ˜¾ç¤º M-D)
    '601127': ('2023-08-01', '2024-01-31'),  # èµ›åŠ›æ–¯ (å†å²ï¼ŒBç«™æ˜¾ç¤º Y-M-D)
    '01810': ('2024-02-01', '2024-05-31')  # å°ç±³ (å†å²ï¼ŒBç«™æ˜¾ç¤º Y-M-D)
}

RAW_DIR = "./raw_data_lake"
REAL_DIR = "./real_data"
if not os.path.exists(REAL_DIR): os.makedirs(REAL_DIR)


# ===========================
# 2. æ ¸å¿ƒæ¸…æ´—å·¥å…·
# ===========================
def clean_count(text):
    """æŠŠ '103.5ä¸‡' è½¬ä¸º 1035000"""
    try:
        text = str(text).strip()
        if 'ä¸‡' in text:
            return int(float(text.replace('ä¸‡', '')) * 10000)
        elif 'äº¿' in text:
            return int(float(text.replace('äº¿', '')) * 100000000)
        else:
            # æå–çº¯æ•°å­—
            nums = re.findall(r'\d+', text)
            return int(nums[0]) if nums else 0
    except:
        return 0


def clean_date(text):
    """
    ã€æ ¸å¿ƒä¿®å¤ã€‘æ™ºèƒ½æ—¥æœŸè§£æ
    1. 2023-9-12 -> 2023-09-12
    2. 9-12      -> 2025-09-12 (è‡ªåŠ¨è¡¥å…¨ä»Šå¹´)
    3. æ˜¨å¤©/å‡ å°æ—¶å‰ -> æ¨ç®—å…·ä½“æ—¥æœŸ
    """
    try:
        text = str(text).strip()
        now = datetime.datetime.now()
        current_year = now.year  # 2025

        # --- A. ç›¸å¯¹æ—¶é—´å¤„ç† ---
        if 'æ˜¨å¤©' in text:
            d = now - datetime.timedelta(days=1)
            return d.strftime('%Y-%m-%d')
        elif 'å°æ—¶å‰' in text or 'åˆ†é’Ÿå‰' in text or 'åˆš' in text:
            return now.strftime('%Y-%m-%d')
        elif 'å¤©å‰' in text:
            days = int(re.findall(r'\d+', text)[0])
            d = now - datetime.timedelta(days=days)
            return d.strftime('%Y-%m-%d')

        # --- B. ç»å¯¹æ—¶é—´å¤„ç† ---
        # 1. ä¼˜å…ˆæ£€æŸ¥æ˜¯å¦åŒ…å«å¹´ä»½ (4ä½æ•°å­—)
        # åŒ¹é…åƒ 2023-9-12, 2024/3/5, 2023å¹´5æœˆ
        year_match = re.search(r'(20\d{2})', text)

        if year_match:
            # æœ‰å¹´ä»½ï¼Œç›´æ¥è§£æ
            # ç»Ÿä¸€æ›¿æ¢åˆ†éš”ç¬¦ä¸º -
            text = text.replace('å¹´', '-').replace('æœˆ', '-').replace('æ—¥', '')
            text = text.replace('/', '-')
            return pd.to_datetime(text).strftime('%Y-%m-%d')

        else:
            # 2. æ²¡æœ‰å¹´ä»½ï¼Œåªæœ‰æœˆ-æ—¥ (å¦‚ 9-12, 11-21)
            # è¿™ç§æƒ…å†µé»˜è®¤æ˜¯ã€ä»Šå¹´ã€‘
            # ç»Ÿä¸€åˆ†éš”ç¬¦
            text = text.replace('æœˆ', '-').replace('æ—¥', '')

            # ç¡®ä¿æ ¼å¼æ˜¯ M-D
            if '-' in text:
                return pd.to_datetime(f"{current_year}-{text}").strftime('%Y-%m-%d')

        return None
    except:
        return None


def get_sentiment(text):
    try:
        return SnowNLP(str(text)).sentiments
    except:
        return 0.5


# ===========================
# 3. ä¸»å¤„ç†é€»è¾‘
# ===========================
def main():
    print("ğŸš€ å¯åŠ¨ Bilibili æ•°æ®æ¸…æ´—ä¸ NLP åˆ†æ (æ—¥æœŸä¿®å¤ç‰ˆ)...")

    for code, (start_dt, end_dt) in TIME_WINDOWS.items():
        raw_path = f"{RAW_DIR}/bili_raw_{code}.csv"
        if not os.path.exists(raw_path):
            print(f"âš ï¸ æœªæ‰¾åˆ°åŸå§‹æ–‡ä»¶: {raw_path}ï¼Œè¯·å…ˆè¿è¡Œ bilibili_crawl.py")
            continue

        print(f"\nğŸ”¨ å¤„ç† {code}...")
        df = pd.read_csv(raw_path)
        print(f"   - åŸå§‹æ•°æ®: {len(df)} æ¡")

        # 1. æ¸…æ´—æ—¥æœŸ (å…³é”®æ­¥éª¤)
        df['date'] = df['raw_date'].apply(clean_date)
        df['date'] = pd.to_datetime(df['date'], errors='coerce')

        # å‰”é™¤æ— æ•ˆæ—¥æœŸ
        df = df.dropna(subset=['date'])

        # 2. æ—¶é—´çª—å£è¿‡æ»¤
        # åªä¿ç•™å¤„äºâ€œçˆ†å‘æœŸâ€å†…çš„è§†é¢‘
        mask = (df['date'] >= pd.to_datetime(start_dt)) & (df['date'] <= pd.to_datetime(end_dt))
        df_valid = df.loc[mask].copy()

        print(f"   - æ¸…æ´—åä¿ç•™ ({start_dt}~{end_dt}): {len(df_valid)} æ¡")

        if df_valid.empty:
            print("   âš ï¸ è¯¥æ—¶é—´æ®µæ— æœ‰æ•ˆè§†é¢‘ï¼Œå¯èƒ½æ˜¯çˆ¬è™«æ²¡æŠ“åˆ°å†å²æ•°æ®ã€‚")
            continue

        # 3. æ¸…æ´—æ•°å€¼æŒ‡æ ‡
        df_valid['view_count'] = df_valid['raw_views'].apply(clean_count)
        df_valid['danmaku_count'] = df_valid['raw_danmaku'].apply(clean_count)

        # 4. æƒ…æ„Ÿæ‰“åˆ†
        df_valid['sentiment'] = df_valid['title'].apply(get_sentiment)

        # 5. è®¡ç®— Bç«™ç‰¹æœ‰çƒ­åº¦ (åŠ æƒ)
        # å¼¹å¹•çš„æƒé‡æ¯”æ’­æ”¾é‡é«˜ï¼Œå› ä¸ºä»£è¡¨æ·±åº¦äº’åŠ¨
        df_valid['bili_buzz'] = df_valid['view_count'] + df_valid['danmaku_count'] * 10

        # 6. æŒ‰æ—¥èšåˆ
        daily = df_valid.groupby('date').agg({
            'bili_buzz': 'sum',
            'sentiment': 'mean',
            'title': 'count'
        }).rename(columns={'title': 'video_num'})

        # ä¿å­˜
        save_path = f"{REAL_DIR}/bilibili_{code}.csv"
        daily.to_csv(save_path)
        print(f"âœ… Bç«™æ•°æ®å·²å°±ç»ª: {save_path}")


if __name__ == "__main__":
    main()
